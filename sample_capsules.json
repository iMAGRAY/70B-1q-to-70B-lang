[
  {
    "text": "Машинное обучение - это раздел искусственного интеллекта, который позволяет компьютерам обучаться без явного программирования.",
    "tags": ["ML", "ИИ", "основы"],
    "rating": 5
  },
  {
    "text": "Нейронные сети состоят из слоев искусственных нейронов, которые обрабатывают информацию параллельно.",
    "tags": ["нейросети", "ИИ", "архитектура"],
    "rating": 5
  },
  {
    "text": "Обучение с учителем требует размеченных данных для тренировки модели.",
    "tags": ["ML", "supervised", "данные"],
    "rating": 4
  },
  {
    "text": "Обучение без учителя находит скрытые закономерности в неразмеченных данных.",
    "tags": ["ML", "unsupervised", "кластеризация"],
    "rating": 4
  },
  {
    "text": "Глубокое обучение использует многослойные нейронные сети для решения сложных задач.",
    "tags": ["deep learning", "нейросети", "ИИ"],
    "rating": 5
  },
  {
    "text": "Переобучение происходит когда модель запоминает тренировочные данные вместо изучения общих закономерностей.",
    "tags": ["ML", "проблемы", "обучение"],
    "rating": 4
  },
  {
    "text": "Регуляризация помогает предотвратить переобучение путем добавления штрафов за сложность модели.",
    "tags": ["ML", "регуляризация", "оптимизация"],
    "rating": 4
  },
  {
    "text": "Градиентный спуск - это алгоритм оптимизации для поиска минимума функции потерь.",
    "tags": ["оптимизация", "алгоритмы", "математика"],
    "rating": 5
  },
  {
    "text": "Сверточные нейронные сети эффективно обрабатывают изображения благодаря локальным фильтрам.",
    "tags": ["CNN", "компьютерное зрение", "нейросети"],
    "rating": 5
  },
  {
    "text": "Рекуррентные нейронные сети имеют память и могут обрабатывать последовательности данных.",
    "tags": ["RNN", "последовательности", "нейросети"],
    "rating": 4
  },
  {
    "text": "Трансформеры используют механизм внимания для эффективной обработки последовательностей.",
    "tags": ["трансформеры", "attention", "NLP"],
    "rating": 5
  },
  {
    "text": "BERT - это двунаправленная модель-трансформер для понимания естественного языка.",
    "tags": ["BERT", "NLP", "трансформеры"],
    "rating": 5
  },
  {
    "text": "GPT - это генеративная предобученная модель-трансформер для создания текста.",
    "tags": ["GPT", "генерация", "трансформеры"],
    "rating": 5
  },
  {
    "text": "Обучение с подкреплением учит агента принимать решения через взаимодействие со средой.",
    "tags": ["RL", "агенты", "решения"],
    "rating": 4
  },
  {
    "text": "Кросс-валидация помогает оценить качество модели на независимых данных.",
    "tags": ["валидация", "оценка", "тестирование"],
    "rating": 4
  },
  {
    "text": "Ансамбли моделей объединяют несколько алгоритмов для повышения точности предсказаний.",
    "tags": ["ансамбли", "модели", "точность"],
    "rating": 4
  },
  {
    "text": "Фичи инжиниринг - это процесс создания и отбора признаков для улучшения модели.",
    "tags": ["признаки", "инжиниринг", "данные"],
    "rating": 4
  },
  {
    "text": "Эмбеддинги представляют слова и объекты в виде векторов в многомерном пространстве.",
    "tags": ["эмбеддинги", "векторы", "представления"],
    "rating": 5
  },
  {
    "text": "Автоэнкодеры сжимают данные в латентное пространство и восстанавливают их обратно.",
    "tags": ["автоэнкодеры", "сжатие", "латентное пространство"],
    "rating": 4
  },
  {
    "text": "Генеративно-состязательные сети состоят из генератора и дискриминатора, обучающихся в конкуренции.",
    "tags": ["GAN", "генерация", "состязательное обучение"],
    "rating": 5
  },
  {
    "text": "Dropout случайно отключает нейроны во время обучения для предотвращения переобучения.",
    "tags": ["dropout", "регуляризация", "нейросети"],
    "rating": 4
  },
  {
    "text": "Батч нормализация нормализует входы слоев для ускорения и стабилизации обучения.",
    "tags": ["batch norm", "нормализация", "оптимизация"],
    "rating": 4
  },
  {
    "text": "Функции активации определяют выходной сигнал нейрона на основе входного сигнала.",
    "tags": ["активация", "нейроны", "функции"],
    "rating": 4
  },
  {
    "text": "Точность, полнота и F1-мера - основные метрики для оценки классификации.",
    "tags": ["метрики", "классификация", "оценка"],
    "rating": 4
  },
  {
    "text": "Градиентный бустинг последовательно строит слабые модели, исправляя ошибки предыдущих.",
    "tags": ["бустинг", "ансамбли", "градиенты"],
    "rating": 4
  },
  {
    "text": "Случайный лес объединяет множество деревьев решений для повышения стабильности предсказаний.",
    "tags": ["случайный лес", "деревья", "ансамбли"],
    "rating": 4
  },
  {
    "text": "Разреженность данных возникает когда большинство значений в матрице равны нулю.",
    "tags": ["разреженность", "данные", "матрицы"],
    "rating": 3
  },
  {
    "text": "Предобученные модели можно дообучать на специфических задачах с помощью transfer learning.",
    "tags": ["transfer learning", "предобучение", "fine-tuning"],
    "rating": 5
  },
  {
    "text": "Квантизация уменьшает точность представления весов модели для экономии памяти.",
    "tags": ["квантизация", "оптимизация", "память"],
    "rating": 3
  },
  {
    "text": "ONNX - это открытый формат для представления моделей машинного обучения.",
    "tags": ["ONNX", "форматы", "совместимость"],
    "rating": 3
  }
] 